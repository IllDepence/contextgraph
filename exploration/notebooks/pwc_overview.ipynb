{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83099c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b312c54",
   "metadata": {},
   "source": [
    "# links-between-papers-and-code.json\n",
    "\n",
    "* contains repository URLs and frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "06878e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ws/ys8950/dev/data/paperswithcode/data/links-between-papers-and-code.json') as f:\n",
    "    df_paper_code_links = pd.DataFrame(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ef057823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_url</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_arxiv_id</th>\n",
       "      <th>paper_url_abs</th>\n",
       "      <th>paper_url_pdf</th>\n",
       "      <th>repo_url</th>\n",
       "      <th>is_official</th>\n",
       "      <th>mentioned_in_paper</th>\n",
       "      <th>mentioned_in_github</th>\n",
       "      <th>framework</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://paperswithcode.com/paper/automatic-pos...</td>\n",
       "      <td>Automatic Post-Editing of Machine Translation:...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://aclanthology.org/D18-1341</td>\n",
       "      <td>https://aclanthology.org/D18-1341.pdf</td>\n",
       "      <td>https://github.com/trangvu/ape-npi</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paper_url  \\\n",
       "0  https://paperswithcode.com/paper/automatic-pos...   \n",
       "\n",
       "                                         paper_title paper_arxiv_id  \\\n",
       "0  Automatic Post-Editing of Machine Translation:...           None   \n",
       "\n",
       "                       paper_url_abs                          paper_url_pdf  \\\n",
       "0  https://aclanthology.org/D18-1341  https://aclanthology.org/D18-1341.pdf   \n",
       "\n",
       "                             repo_url  is_official  mentioned_in_paper  \\\n",
       "0  https://github.com/trangvu/ape-npi        False               False   \n",
       "\n",
       "   mentioned_in_github framework  \n",
       "0                False        tf  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paper_code_links.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "9570bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arXiv ID to repo URL export for npo\n",
    "df_arxiv_to_repo = df_paper_code_links[df_paper_code_links.paper_arxiv_id.notna()][['paper_arxiv_id', 'repo_url']]\n",
    "df_arxiv_to_repo['full_text_fn'] = df_arxiv_to_repo.paper_arxiv_id.apply(lambda x: x.replace('/', '') + '.txt')\n",
    "df_arxiv_to_repo.to_csv('arXiv_fulltext_to_repo.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "23f4177c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papers:\t\t\t125,524\n",
      "papers w/ arXiv ID:\t119,903\n",
      "frameworks:\t\tnone\t(54,108)\n",
      "\t\t\tpytorch\t(44,026)\n",
      "\t\t\ttf\t(25,012)\n",
      "\t\t\tmxnet\t(601)\n",
      "\t\t\tpaddle\t(534)\n",
      "\t\t\ttorch\t(505)\n",
      "\t\t\tcaffe2\t(371)\n",
      "\t\t\tjax\t(367)\n"
     ]
    }
   ],
   "source": [
    "print(f'papers:\\t\\t\\t{df_paper_code_links.shape[0]:,}')\n",
    "print(f'papers w/ arXiv ID:\\t{df_paper_code_links[df_paper_code_links.paper_arxiv_id.notna()].shape[0]:,}')\n",
    "print('frameworks:\\t\\t{}'.format(\n",
    "    '\\n\\t\\t\\t'.join(\n",
    "        ['{}\\t({:,})'.format(k, v) for k, v in df_paper_code_links['framework'].value_counts().iteritems()]\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538eb0e",
   "metadata": {},
   "source": [
    "# methods.json\n",
    "\n",
    "* paper-method associations are given in papers-with-abstracts.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6e4f92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ws/ys8950/dev/data/paperswithcode/data/methods.json') as f:\n",
    "    df_methods = pd.DataFrame(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "126f664c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "methods: 1,802\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>paper</th>\n",
       "      <th>introduced_year</th>\n",
       "      <th>source_url</th>\n",
       "      <th>source_title</th>\n",
       "      <th>code_snippet_url</th>\n",
       "      <th>collections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://paperswithcode.com/method/densenas-a</td>\n",
       "      <td>DenseNAS-A</td>\n",
       "      <td>DenseNAS-A</td>\n",
       "      <td>**DenseNAS-A** is a mobile convolutional neura...</td>\n",
       "      <td>densely-connected-search-space-for-more</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://github.com/JaminFong/DenseNAS/blob/e47...</td>\n",
       "      <td>[{'collection': 'Convolutional Neural Networks...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            url        name   full_name  \\\n",
       "0  https://paperswithcode.com/method/densenas-a  DenseNAS-A  DenseNAS-A   \n",
       "\n",
       "                                         description  \\\n",
       "0  **DenseNAS-A** is a mobile convolutional neura...   \n",
       "\n",
       "                                     paper  introduced_year source_url  \\\n",
       "0  densely-connected-search-space-for-more             2000       None   \n",
       "\n",
       "  source_title                                   code_snippet_url  \\\n",
       "0         None  https://github.com/JaminFong/DenseNAS/blob/e47...   \n",
       "\n",
       "                                         collections  \n",
       "0  [{'collection': 'Convolutional Neural Networks...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'methods: {df_methods.shape[0]:,}')\n",
    "df_methods.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc0bea3",
   "metadata": {},
   "source": [
    "# datasets.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "89519101",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ws/ys8950/dev/data/paperswithcode/data/datasets.json') as f:\n",
    "    df_datasets = pd.DataFrame(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a32dc301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: 5,124\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>homepage</th>\n",
       "      <th>description</th>\n",
       "      <th>paper</th>\n",
       "      <th>introduced_date</th>\n",
       "      <th>warning</th>\n",
       "      <th>modalities</th>\n",
       "      <th>tasks</th>\n",
       "      <th>languages</th>\n",
       "      <th>variants</th>\n",
       "      <th>num_papers</th>\n",
       "      <th>data_loaders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://paperswithcode.com/dataset/mnist</td>\n",
       "      <td>MNIST</td>\n",
       "      <td></td>\n",
       "      <td>http://yann.lecun.com/exdb/mnist/</td>\n",
       "      <td>The **MNIST** database (**Modified National In...</td>\n",
       "      <td>{'title': 'Gradient-based learning applied to ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Images]</td>\n",
       "      <td>[{'task': 'Image Classification', 'url': 'http...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[USPS-to-MNIST, MNIST-to-USPS, Rotating MNIST,...</td>\n",
       "      <td>4673</td>\n",
       "      <td>[{'url': 'https://huggingface.co/datasets/mnis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        url   name full_name  \\\n",
       "0  https://paperswithcode.com/dataset/mnist  MNIST             \n",
       "\n",
       "                            homepage  \\\n",
       "0  http://yann.lecun.com/exdb/mnist/   \n",
       "\n",
       "                                         description  \\\n",
       "0  The **MNIST** database (**Modified National In...   \n",
       "\n",
       "                                               paper introduced_date warning  \\\n",
       "0  {'title': 'Gradient-based learning applied to ...            None    None   \n",
       "\n",
       "  modalities                                              tasks languages  \\\n",
       "0   [Images]  [{'task': 'Image Classification', 'url': 'http...        []   \n",
       "\n",
       "                                            variants  num_papers  \\\n",
       "0  [USPS-to-MNIST, MNIST-to-USPS, Rotating MNIST,...        4673   \n",
       "\n",
       "                                        data_loaders  \n",
       "0  [{'url': 'https://huggingface.co/datasets/mnis...  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'datasets: {df_datasets.shape[0]:,}')\n",
    "df_datasets.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b91be0",
   "metadata": {},
   "source": [
    "# papers-with-abstracts.json\n",
    "\n",
    "* contains for each paper\n",
    "    * arXiv ID\n",
    "    * methods\n",
    "    * tasks\n",
    "* does not contain\n",
    "    * datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c7ae9da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ws/ys8950/dev/data/paperswithcode/data/papers-with-abstracts.json') as f:\n",
    "    df_paper_abstracts = pd.DataFrame(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d0453c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_url</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url_abs</th>\n",
       "      <th>url_pdf</th>\n",
       "      <th>proceeding</th>\n",
       "      <th>authors</th>\n",
       "      <th>tasks</th>\n",
       "      <th>date</th>\n",
       "      <th>methods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://paperswithcode.com/paper/dynamic-netwo...</td>\n",
       "      <td>1805.10616</td>\n",
       "      <td>Dynamic Network Model from Partial Observations</td>\n",
       "      <td>Can evolving networks be inferred and modeled ...</td>\n",
       "      <td>http://arxiv.org/abs/1805.10616v4</td>\n",
       "      <td>http://arxiv.org/pdf/1805.10616v4.pdf</td>\n",
       "      <td>NeurIPS 2018 12</td>\n",
       "      <td>[Elahe Ghalebi, Baharan Mirzasoleiman, Radu Gr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paper_url    arxiv_id  \\\n",
       "0  https://paperswithcode.com/paper/dynamic-netwo...  1805.10616   \n",
       "\n",
       "                                             title  \\\n",
       "0  Dynamic Network Model from Partial Observations   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Can evolving networks be inferred and modeled ...   \n",
       "\n",
       "                             url_abs                                url_pdf  \\\n",
       "0  http://arxiv.org/abs/1805.10616v4  http://arxiv.org/pdf/1805.10616v4.pdf   \n",
       "\n",
       "        proceeding                                            authors tasks  \\\n",
       "0  NeurIPS 2018 12  [Elahe Ghalebi, Baharan Mirzasoleiman, Radu Gr...    []   \n",
       "\n",
       "         date methods  \n",
       "0  2018-05-27      []  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paper_abstracts.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "64c1aacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papers:\t\t\t260,382\n",
      "papers w/ arXiv ID:\t210,123\n"
     ]
    }
   ],
   "source": [
    "print(f'papers:\\t\\t\\t{df_paper_abstracts.shape[0]:,}')\n",
    "print(f'papers w/ arXiv ID:\\t{df_paper_abstracts[df_paper_abstracts.arxiv_id.notna()].shape[0]:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce05bb3a",
   "metadata": {},
   "source": [
    "# evaluation-tables.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e50de970",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ws/ys8950/dev/data/paperswithcode/data/evaluation-tables.json') as f:\n",
    "    df_eval_tables = pd.DataFrame(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "57caff6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papers:\t\t\t1,280\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>subtasks</th>\n",
       "      <th>source_link</th>\n",
       "      <th>task</th>\n",
       "      <th>description</th>\n",
       "      <th>datasets</th>\n",
       "      <th>synonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Methodology, Natural Language Processing, Com...</td>\n",
       "      <td>[{'categories': ['Methodology', 'Natural Langu...</td>\n",
       "      <td>None</td>\n",
       "      <td>Optical Character Recognition</td>\n",
       "      <td>Optical character recognition or optical chara...</td>\n",
       "      <td>[{'dataset_links': [{'url': 'https://paperswit...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          categories  \\\n",
       "0  [Methodology, Natural Language Processing, Com...   \n",
       "\n",
       "                                            subtasks source_link  \\\n",
       "0  [{'categories': ['Methodology', 'Natural Langu...        None   \n",
       "\n",
       "                            task  \\\n",
       "0  Optical Character Recognition   \n",
       "\n",
       "                                         description  \\\n",
       "0  Optical character recognition or optical chara...   \n",
       "\n",
       "                                            datasets synonyms  \n",
       "0  [{'dataset_links': [{'url': 'https://paperswit...       []  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'papers:\\t\\t\\t{df_eval_tables.shape[0]:,}')\n",
    "df_eval_tables.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1da6204",
   "metadata": {},
   "source": [
    "‌  \n",
    "‌  \n",
    "\n",
    "### what info is where\n",
    "\n",
    "* arXiv ID → method: `papers-with-abstracts`\n",
    "* arXiv ID → task: `papers-with-abstracts`\n",
    "* arXiv ID → dataset: `(not given, manually crawled)`\n",
    "\n",
    "\n",
    "* framework: `links-between-papers-and-code`\n",
    "* repo URLs: `links-between-papers-and-code`\n",
    "\n",
    "‌  \n",
    "‌  \n",
    "‌  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a42101f",
   "metadata": {},
   "source": [
    "# crawled dataset paper associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fdca31d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ws/ys8950/dev/data/paperswithcode/data/crawled-dataset-papers.json') as f:\n",
    "    dataset_papers = json.load(f)\n",
    "# {\n",
    "#     <dataset-url>:\n",
    "#         {\n",
    "#             'url': <paper-path/slug>,\n",
    "#             ...\n",
    "#         }\n",
    "#     ...\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8ccc0f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and clean reverse dict\n",
    "paper_datasets = {}\n",
    "for dataset_url, paper_list in dataset_papers.items():\n",
    "    for paper in paper_list:\n",
    "        dataset_slug = dataset_url.replace('https://paperswithcode.com/dataset/', '')\n",
    "        paper_slug = paper['url'].replace('/paper/', '')\n",
    "        if paper_slug not in paper_datasets:\n",
    "            paper_datasets[paper_slug] = []\n",
    "        paper_datasets[paper_slug].append(dataset_slug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b326a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend paper abstracts dataframe\n",
    "def add_dataset_info(row):\n",
    "    paper_slug = row['paper_url'].replace('https://paperswithcode.com/paper/', '')\n",
    "    paper_dataset_slugs = paper_datasets.get(paper_slug, [])\n",
    "    paper_dataset_objects = [\n",
    "        df_datasets[df_datasets.url == 'https://paperswithcode.com/dataset/'+slug].iloc[0].to_dict()\n",
    "        for slug\n",
    "        in paper_dataset_slugs\n",
    "    ]\n",
    "    row['datasets'] = paper_dataset_objects\n",
    "    return row\n",
    "\n",
    "df_paper_abstracts_extended = df_paper_abstracts.apply(add_dataset_info, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "cb79ec10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papers:\t\t\t\t260,382\n",
      "papers w/ tasks:\t\t159,351\n",
      "papers w/ methods:\t\t42,119\n",
      "papers w/ datasets:\t\t69,829\n",
      "papers w/ tasks & methods:\t30,854\n",
      "papers w/ tasks & datasets:\t56,717\n",
      "papers w/ methods & tasks:\t30,854\n",
      "papers w/ methods & datasets:\t17,270\n",
      "papers w/ datasets & tasks:\t56,717\n",
      "papers w/ datasets & methods:\t17,270\n",
      "papers w/ all three:\t\t14,322\n",
      "papers w/ any:\t\t\t180,780\n"
     ]
    }
   ],
   "source": [
    "print('papers:\\t\\t\\t\\t{:,}'.format(\n",
    "    df_paper_abstracts_extended.shape[0]\n",
    "))\n",
    "for typ in ['tasks', 'methods', 'datasets']:\n",
    "    print('papers w/ {}:\\t\\t{:,}'.format(\n",
    "        typ,\n",
    "        df_paper_abstracts_extended[df_paper_abstracts_extended[typ].apply(lambda x: len(x)) > 0].shape[0]\n",
    "    ))\n",
    "for typa in ['tasks', 'methods', 'datasets']:\n",
    "    for typb in ['tasks', 'methods', 'datasets']:\n",
    "        if typa == typb:\n",
    "            continue\n",
    "        print('papers w/ {} & {}:\\t{:,}'.format(\n",
    "            typa,\n",
    "            typb,\n",
    "            df_paper_abstracts_extended[\n",
    "                (df_paper_abstracts_extended[typa].apply(lambda x: len(x)) > 0)\n",
    "                &\n",
    "                (df_paper_abstracts_extended[typb].apply(lambda x: len(x)) > 0)\n",
    "            ].shape[0]\n",
    "        ))\n",
    "print('papers w/ all three:\\t\\t{:,}'.format(\n",
    "            df_paper_abstracts_extended[\n",
    "                (df_paper_abstracts_extended['tasks'].apply(lambda x: len(x)) > 0)\n",
    "                &\n",
    "                (df_paper_abstracts_extended['methods'].apply(lambda x: len(x)) > 0)\n",
    "                &\n",
    "                (df_paper_abstracts_extended['datasets'].apply(lambda x: len(x)) > 0)\n",
    "            ].shape[0]\n",
    "))\n",
    "print('papers w/ any:\\t\\t\\t{:,}'.format(\n",
    "            df_paper_abstracts_extended[\n",
    "                (df_paper_abstracts_extended['tasks'].apply(lambda x: len(x)) > 0)\n",
    "                |\n",
    "                (df_paper_abstracts_extended['methods'].apply(lambda x: len(x)) > 0)\n",
    "                |\n",
    "                (df_paper_abstracts_extended['datasets'].apply(lambda x: len(x)) > 0)\n",
    "            ].shape[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f8a269fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/ws/ys8950/dev/data/paperswithcode/data/papers-with-abstracts-extended.json', 'w') as f:\n",
    "#     df_paper_abstracts_extended.to_json(f, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eee21a",
   "metadata": {},
   "source": [
    "# How to construct relations between entities used in papers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "10373860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_url</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url_abs</th>\n",
       "      <th>url_pdf</th>\n",
       "      <th>proceeding</th>\n",
       "      <th>authors</th>\n",
       "      <th>tasks</th>\n",
       "      <th>date</th>\n",
       "      <th>methods</th>\n",
       "      <th>datasets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://paperswithcode.com/paper/modularity-ma...</td>\n",
       "      <td>1806.06765</td>\n",
       "      <td>Modularity Matters: Learning Invariant Relatio...</td>\n",
       "      <td>We focus on two supervised visual reasoning ta...</td>\n",
       "      <td>http://arxiv.org/abs/1806.06765v1</td>\n",
       "      <td>http://arxiv.org/pdf/1806.06765v1.pdf</td>\n",
       "      <td>None</td>\n",
       "      <td>[Jason Jo, Vikas Verma, Yoshua Bengio]</td>\n",
       "      <td>[Relational Reasoning, Visual Reasoning]</td>\n",
       "      <td>2018-06-18</td>\n",
       "      <td>[{'name': 'Average Pooling', 'full_name': 'Ave...</td>\n",
       "      <td>[{'url': 'https://paperswithcode.com/dataset/m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://paperswithcode.com/paper/a-memory-netw...</td>\n",
       "      <td>1805.02838</td>\n",
       "      <td>A Memory Network Approach for Story-based Temp...</td>\n",
       "      <td>We address the problem of story-based temporal...</td>\n",
       "      <td>http://arxiv.org/abs/1805.02838v3</td>\n",
       "      <td>http://arxiv.org/pdf/1805.02838v3.pdf</td>\n",
       "      <td>CVPR 2018</td>\n",
       "      <td>[Sang-ho Lee, Jinyoung Sung, Youngjae Yu, Gunh...</td>\n",
       "      <td>[Video Summarization]</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>[{'name': 'Memory Network', 'full_name': 'Memo...</td>\n",
       "      <td>[{'url': 'https://paperswithcode.com/dataset/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>https://paperswithcode.com/paper/on-enhancing-...</td>\n",
       "      <td>1806.06626</td>\n",
       "      <td>On Enhancing Speech Emotion Recognition using ...</td>\n",
       "      <td>Generative Adversarial Networks (GANs) have ga...</td>\n",
       "      <td>http://arxiv.org/abs/1806.06626v1</td>\n",
       "      <td>http://arxiv.org/pdf/1806.06626v1.pdf</td>\n",
       "      <td>None</td>\n",
       "      <td>[Saurabh Sahu, Rahul Gupta, Carol Espy-Wilson]</td>\n",
       "      <td>[Emotion Recognition, Speech Emotion Recognition]</td>\n",
       "      <td>2018-06-18</td>\n",
       "      <td>[{'name': 'Convolution', 'full_name': 'Convolu...</td>\n",
       "      <td>[{'url': 'https://paperswithcode.com/dataset/i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            paper_url    arxiv_id  \\\n",
       "15  https://paperswithcode.com/paper/modularity-ma...  1806.06765   \n",
       "17  https://paperswithcode.com/paper/a-memory-netw...  1805.02838   \n",
       "30  https://paperswithcode.com/paper/on-enhancing-...  1806.06626   \n",
       "\n",
       "                                                title  \\\n",
       "15  Modularity Matters: Learning Invariant Relatio...   \n",
       "17  A Memory Network Approach for Story-based Temp...   \n",
       "30  On Enhancing Speech Emotion Recognition using ...   \n",
       "\n",
       "                                             abstract  \\\n",
       "15  We focus on two supervised visual reasoning ta...   \n",
       "17  We address the problem of story-based temporal...   \n",
       "30  Generative Adversarial Networks (GANs) have ga...   \n",
       "\n",
       "                              url_abs                                url_pdf  \\\n",
       "15  http://arxiv.org/abs/1806.06765v1  http://arxiv.org/pdf/1806.06765v1.pdf   \n",
       "17  http://arxiv.org/abs/1805.02838v3  http://arxiv.org/pdf/1805.02838v3.pdf   \n",
       "30  http://arxiv.org/abs/1806.06626v1  http://arxiv.org/pdf/1806.06626v1.pdf   \n",
       "\n",
       "   proceeding                                            authors  \\\n",
       "15       None             [Jason Jo, Vikas Verma, Yoshua Bengio]   \n",
       "17  CVPR 2018  [Sang-ho Lee, Jinyoung Sung, Youngjae Yu, Gunh...   \n",
       "30       None     [Saurabh Sahu, Rahul Gupta, Carol Espy-Wilson]   \n",
       "\n",
       "                                                tasks        date  \\\n",
       "15           [Relational Reasoning, Visual Reasoning]  2018-06-18   \n",
       "17                              [Video Summarization]  2018-05-08   \n",
       "30  [Emotion Recognition, Speech Emotion Recognition]  2018-06-18   \n",
       "\n",
       "                                              methods  \\\n",
       "15  [{'name': 'Average Pooling', 'full_name': 'Ave...   \n",
       "17  [{'name': 'Memory Network', 'full_name': 'Memo...   \n",
       "30  [{'name': 'Convolution', 'full_name': 'Convolu...   \n",
       "\n",
       "                                             datasets  \n",
       "15  [{'url': 'https://paperswithcode.com/dataset/m...  \n",
       "17  [{'url': 'https://paperswithcode.com/dataset/i...  \n",
       "30  [{'url': 'https://paperswithcode.com/dataset/i...  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haveitall = df_paper_abstracts_extended[\n",
    "    (df_paper_abstracts_extended['tasks'].apply(lambda x: len(x)) > 0)\n",
    "    &\n",
    "    (df_paper_abstracts_extended['methods'].apply(lambda x: len(x)) > 0)\n",
    "    &\n",
    "    (df_paper_abstracts_extended['datasets'].apply(lambda x: len(x)) > 0)\n",
    "]\n",
    "haveitall[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "16318876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MNIST', 'SHAPES']\n",
      "['Relational Reasoning', 'Visual Reasoning']\n",
      "['Average Pooling', 'ReLU', '1x1 Convolution', 'Batch Normalization', 'Bottleneck Residual Block', 'Global Average Pooling', 'Residual Block', 'Kaiming Initialization', 'Max Pooling', 'Residual Connection', 'Convolution', 'ResNet']\n"
     ]
    }
   ],
   "source": [
    "hasitall = haveitall.iloc[0]\n",
    "# https://paperswithcode.com/paper/modularity-matters-learning-invariant\n",
    "print([d['name'] for d in hasitall.datasets])\n",
    "print(hasitall.tasks)\n",
    "print([m['name'] for m in hasitall.methods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "53c3e4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST\n",
      "['Image Classification', 'Image Generation', 'Text Classification', 'Speech Recognition', 'Domain Adaptation', 'Graph Classification', 'Anomaly Detection', 'Image Clustering', 'Fine-Grained Image Classification', 'Feature Selection', 'Neural Architecture Search', 'Density Estimation', 'Continual Learning', 'Core set discovery', 'Stochastic Optimization', 'Unsupervised Anomaly Detection', 'Adversarial Defense', 'Video Prediction', 'Token Classification', 'Sequence-to-sequence Language Modeling', 'Unsupervised Image Classification', 'Network Pruning', 'Classification with Binary Weight Network', 'Sequential Image Classification', 'Continuously Indexed Domain Adaptation', 'Unsupervised Image-To-Image Translation', 'Hard-label Attack', 'Structured Prediction', 'One-Shot Learning', 'Handwritten Digit Recognition', 'Unsupervised MNIST', 'Rotated MNIST', 'Superpixel Image Classification', 'Summarization', 'NER', 'POS', 'SENTER', 'Iloko Speech Recognition']\n",
      "SHAPES\n",
      "['Question Answering', 'Visual Question Answering', 'Time Series Classification', 'Visual Reasoning']\n"
     ]
    }
   ],
   "source": [
    "for d in hasitall.datasets:\n",
    "    print(d['name'])\n",
    "    print([t['task'] for t in d['tasks']])\n",
    "# -> if dataset task in paper's used tasks, create tripe (task, performed_using, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a465f90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched:\n",
      "('Speech Emotion Recognition', 'performed_using', 'IEMOCAP')\n",
      "- - - - -\n",
      "tasks not mached: ['Emotion Recognition']\n",
      "datasets not mached: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# nice result for https://paperswithcode.com/paper/glomo-unsupervisedly-learned-relational\n",
    "# ('Image Classification', 'performed_using', 'ImageNet')\n",
    "# ('Question Answering', 'performed_using', 'SQuAD')\n",
    "# ('Natural Language Inference', 'performed_using', 'SNLI')\n",
    "# ('Sentiment Analysis', 'performed_using', 'IMDb Movie Reviews')\n",
    "# - - - - -\n",
    "# tasks not mached: ['Transfer Learning', 'Word Embeddings']\n",
    "# datasets not mached: []\n",
    "# - - - - -\n",
    "\n",
    "\n",
    "i = 0\n",
    "for _, ppr in haveitall.iterrows():\n",
    "    if i < 2:\n",
    "        i += 1\n",
    "        continue\n",
    "    triples = []\n",
    "    tasks_matched = []\n",
    "    datasets_matched = []\n",
    "    debug_result = 'matched:\\n'\n",
    "    for d in ppr.datasets:\n",
    "        for t in d['tasks']:\n",
    "            if t['task'] in ppr.tasks:\n",
    "                datasets_matched.append(d['name'])\n",
    "                tasks_matched.append(t['task'])\n",
    "                triples.append(\n",
    "                    (t['task'], 'performed_using', d['name'])\n",
    "                )\n",
    "                debug_result += '{}\\n'.format((t['task'], 'performed_using', d['name']))\n",
    "    debug_result += '- - - - -\\n'\n",
    "    debug_result += 'tasks not mached: {}\\n'.format(\n",
    "        list(set(ppr.tasks).difference(set(tasks_matched)))\n",
    "    )\n",
    "    debug_result += 'datasets not mached: {}\\n'.format(\n",
    "        list(set([d['name'] for d in ppr.datasets]).difference(set(datasets_matched)))\n",
    "    )\n",
    "    print(debug_result)\n",
    "    # for m in ppr.methods:\n",
    "    #     for t in ppr.tasks:\n",
    "    #         triples.append(\n",
    "    #             (m['name'], 'used_for', t)\n",
    "    #         )\n",
    "    #         # print((m['name'], 'used_for', t))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
